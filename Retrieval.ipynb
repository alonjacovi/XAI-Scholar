{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semanticscholar import SemanticScholar\n",
    "import pickle as pkl\n",
    "import csv\n",
    "import json\n",
    "from difflib import SequenceMatcher as sm\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "from collections import Counter\n",
    "\n",
    "from IPython.display import display, HTML\n",
    "display(HTML(\"<style>div.output_area pre {white-space: pre;}</style>\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0deb1265",
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = SemanticScholar()\n",
    "fields = ['title', 'abstract', 'year', 'venue', 'publicationVenue', 'externalIds', 'url',\n",
    "          'journal', 'referenceCount', 'citationCount', 'influentialCitationCount',\n",
    "          'fieldsOfStudy', 'authors', 's2FieldsOfStudy', 'publicationTypes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a27cb0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieving papers from SS with keyword queries\n",
    "\n",
    "keywords_xai = [\n",
    "    \" xai \", \"(xai)\", \"hcxai\", \"explainability\", \n",
    "    \"interpretability\", \n",
    "    \"explainable ai\",\n",
    "    \"explainable artificial intelligence\",\n",
    "    \"interpretable ml\", \"interpretable machine learning\", \"interpretable model\",\n",
    "    \"feature attribution\", \"feature importance\", \"global explanation\", \"local explanation\",\n",
    "    \"local interpretation\", \"global interpretation\",\n",
    "    \"model explanation\", \"model interpretation\", \"saliency\", \"counterfactual explanation\"]\n",
    "\n",
    "banned = [\"/xai/xai\", \"xai-xai\", \"xai xai\", \"workshop\", \"proceedings\"]\n",
    "\n",
    "papers = {}\n",
    "\n",
    "for query in keywords_xai:\n",
    "    print(\"Retrieving papers with query:\", query)\n",
    "\n",
    "    res = ss.search_paper(query, fields=fields)\n",
    "    \n",
    "    for i,x in tqdm(enumerate(res)):\n",
    "        title_lower = f\" {x.title.lower()} {x.abstract.lower() if x.abstract else ''} \"\n",
    "        \n",
    "        count = 0\n",
    "        for keyword in keywords_xai:\n",
    "            if keyword in title_lower:\n",
    "                count += 1\n",
    "        for keyword in banned:\n",
    "            if keyword in title_lower:\n",
    "                count = 0\n",
    "        \n",
    "        if count < 2:\n",
    "            continue\n",
    "\n",
    "        x = dict(x)\n",
    "        if 'embedding' in x:\n",
    "            del x['embedding']\n",
    "            \n",
    "        if x.paperId not in papers:\n",
    "            papers[x.paperId] = x\n",
    "            \n",
    "    print(\"# papers:\", len(papers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6ddbb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell performs one round of citation expansion based on a set of seed papers\n",
    "# For the XAI-Scholar dataset, I performed continuous expansion runs until an empty round (no new papers found)\n",
    "\n",
    "citation_expansion_seed = papers\n",
    "\n",
    "expanded_papers = {}\n",
    "\n",
    "for pid in tqdm(citation_expansion_seed):\n",
    "    # The paper dicts returned by \"search_paper()\" don't include references and citations,\n",
    "    # so we need to retrieve them separately.\n",
    "    full_paper = dict(ss.get_paper(pid))\n",
    "    expanded_papers[pid] = full_paper\n",
    "    \n",
    "    if 'references' in full_paper:\n",
    "        refs = full_paper['references']\n",
    "    else:\n",
    "        refs = []\n",
    "        \n",
    "    if 'citations' in full_paper:\n",
    "        cites = full_paper['citations']\n",
    "    else:\n",
    "        cites = []\n",
    "        \n",
    "    for paper in refs + cites:\n",
    "        pid2 = paper['paperId']\n",
    "        \n",
    "        if pid2 in expanded_papers or pid2 in citation_expansion_seed:\n",
    "            continue\n",
    "    \n",
    "        title = paper['title']\n",
    "        abstract = paper['abstract'] if paper['abstract'] else ''\n",
    "        title_lower = f\" {title.lower()} {abstract.lower() if x['abstract'] else ''} \"\n",
    "        \n",
    "        count = 0\n",
    "        for keyword in keywords_xai:\n",
    "            if keyword in title_lower:\n",
    "                count += 1\n",
    "        for keyword in banned:\n",
    "            if keyword in title_lower:\n",
    "                count = 0\n",
    "\n",
    "        if count < 2:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        x = dict(ss.get_paper(pid2))\n",
    "        \n",
    "        if 'embedding' in x:\n",
    "            del x['embedding']\n",
    "        \n",
    "        expanded_papers[pid2] = paper\n",
    "        print(\"Hey :)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3269246",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
